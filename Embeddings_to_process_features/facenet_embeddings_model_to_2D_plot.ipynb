{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import cPickle as pickle\n",
    "import pickle\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image, ImageDraw\n",
    "from sklearn.manifold import TSNE\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will load our image paths and feature vectors from the previous notebook into memory. We can print their contents to get an idea of what they look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_features :  30000 512\n",
      "image: /home/kangeunsu/progressive_growing_of_gans/celeba-hq-1024x1024_test_extract/img00000000.png, features: -0.08,0.00,-0.03,-0.02... \n",
      "image: /home/kangeunsu/progressive_growing_of_gans/celeba-hq-1024x1024_test_extract/img00000001.png, features: -0.05,0.07,-0.02,0.07... \n",
      "image: /home/kangeunsu/progressive_growing_of_gans/celeba-hq-1024x1024_test_extract/img00000002.png, features: -0.06,0.03,0.00,0.05... \n",
      "image: /home/kangeunsu/progressive_growing_of_gans/celeba-hq-1024x1024_test_extract/img00000003.png, features: -0.08,0.03,0.01,0.06... \n",
      "image: /home/kangeunsu/progressive_growing_of_gans/celeba-hq-1024x1024_test_extract/img00000004.png, features: -0.03,0.05,-0.04,0.07... \n"
     ]
    }
   ],
   "source": [
    "# ORIGINAL DATASET\n",
    "path = '/home/kangeunsu/facenet/embeddings_from_celeb_30k_noflip_160px.p'\n",
    "directory = \"/home/kangeunsu/progressive_growing_of_gans/celeba-hq-1024x1024_test_extract/\"\n",
    "\n",
    "# load features\n",
    "full_features = pickle.load(open(path, 'rb'), encoding='latin1')\n",
    "full_features = full_features[0]\n",
    "print(\"full_features : \",len(full_features), len(full_features[0]))\n",
    "\n",
    "import fnmatch\n",
    "# load images\n",
    "files = sorted(os.listdir(directory))\n",
    "frame_files = fnmatch.filter(files, '*.png')\n",
    "full_paths = [directory+file for file in frame_files]\n",
    "images_mine = full_paths\n",
    "\n",
    "images_ORIG_loaded = images_mine\n",
    "pca_features_ORIG = full_features\n",
    "\n",
    "for i, f in list(zip(images_ORIG_loaded, pca_features_ORIG))[0:5]:\n",
    "    print(\"image: %s, features: %0.2f,%0.2f,%0.2f,%0.2f... \"%(i, f[0], f[1], f[2], f[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_features :  100000 512\n",
      "image: /home/kangeunsu/CelebAHQ_generated_images/200-celebahq-1024x1024/100k_resized_generated/000000.png, features: -0.02,-0.01,-0.03,0.07... \n",
      "image: /home/kangeunsu/CelebAHQ_generated_images/200-celebahq-1024x1024/100k_resized_generated/000001.png, features: -0.08,-0.02,-0.01,0.03... \n",
      "image: /home/kangeunsu/CelebAHQ_generated_images/200-celebahq-1024x1024/100k_resized_generated/000002.png, features: -0.01,0.02,-0.06,0.06... \n",
      "image: /home/kangeunsu/CelebAHQ_generated_images/200-celebahq-1024x1024/100k_resized_generated/000003.png, features: 0.03,-0.05,-0.07,0.04... \n",
      "image: /home/kangeunsu/CelebAHQ_generated_images/200-celebahq-1024x1024/100k_resized_generated/000004.png, features: -0.02,0.01,-0.03,0.07... \n"
     ]
    }
   ],
   "source": [
    "# GENERATED DATASET\n",
    "#1.3G Apr 20 14:07 embeddings_from_100k_generated_images_no_flips.p\n",
    "path = '/home/kangeunsu/facenet/embeddings_from_100k_generated_images_no_flips.p'\n",
    "#directory = \"/home/kangeunsu/CelebAHQ_generated_images/200-celebahq-1024x1024/100k_generated/\"\n",
    "directory = \"/home/kangeunsu/CelebAHQ_generated_images/200-celebahq-1024x1024/100k_resized_generated/\" # not the source images = but downscaled ones, which can serve as tiles\n",
    "\n",
    "# load features\n",
    "full_features = pickle.load(open(path, 'rb'), encoding='latin1')\n",
    "full_features = full_features[0]\n",
    "print(\"full_features : \",len(full_features), len(full_features[0]))\n",
    "\n",
    "import fnmatch\n",
    "# load images\n",
    "files = sorted(os.listdir(directory))\n",
    "frame_files = fnmatch.filter(files, '*.png')\n",
    "full_paths = [directory+file for file in frame_files]\n",
    "images_mine = full_paths\n",
    "\n",
    "images_GEN_loaded = images_mine\n",
    "pca_features_GEN = full_features\n",
    "\n",
    "for i, f in list(zip(images_GEN_loaded, pca_features_GEN))[0:5]:\n",
    "    print(\"image: %s, features: %0.2f,%0.2f,%0.2f,%0.2f... \"%(i, f[0], f[1], f[2], f[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000 100000 30000 100000\n",
      "30000 100000\n"
     ]
    }
   ],
   "source": [
    "num_images_to_plot_ORIG = 30000\n",
    "num_images_to_plot_GEN = 30000 # should be fair representation\n",
    "print(len(images_ORIG_loaded), len(images_GEN_loaded), len(pca_features_ORIG), len(pca_features_GEN))\n",
    "\n",
    "y_original = np.ones(len(pca_features_ORIG))\n",
    "y_generated = np.zeros(len(pca_features_GEN))\n",
    "\n",
    "print(len(y_original), len(y_generated))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our dataset that we've loaded, there are 9144 images. Although in principle, t-SNE works with any number of images, it's difficult to place that many tiles in a single image. So instead, we will take a random subset of 1000 images and plot those on a t-SNE instead. This step is optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images:  30000 orig and  100000 gen\n",
      "Total features:  30000 orig and  100000 gen\n",
      "shuffled originals\n",
      "shuffled generated\n",
      "After shuffling:\n",
      "Shuffled Original: images 30000 features 30000 x 512\n",
      "Shuffled Generated: images 30000 features 30000 x 512\n",
      "Combined: images 60000 features 60000 x 512\n",
      "Y:  60000\n"
     ]
    }
   ],
   "source": [
    "# Shuffle\n",
    "\n",
    "images_ORIG_shuffled = images_ORIG_loaded\n",
    "images_GEN_shuffled = images_GEN_loaded\n",
    "print(\"Total images: \", len(images_ORIG_loaded), \"orig and \", len(images_GEN_loaded), \"gen\")\n",
    "pca_features_ORIG_shuffled = pca_features_ORIG\n",
    "pca_features_GEN_shuffled = pca_features_GEN\n",
    "print(\"Total features: \", len(pca_features_ORIG), \"orig and \", len(pca_features_GEN), \"gen\")\n",
    "\n",
    "y_original_shuffled = y_original\n",
    "y_generated_shuffled = y_generated\n",
    "\n",
    "if len(images_ORIG_loaded) >= num_images_to_plot_ORIG:\n",
    "    sort_order = sorted(random.sample(range(len(images_ORIG_shuffled)), num_images_to_plot_ORIG))\n",
    "    images_ORIG_shuffled = [images_ORIG_shuffled[i] for i in sort_order]\n",
    "    pca_features_ORIG_shuffled = [pca_features_ORIG_shuffled[i] for i in sort_order]\n",
    "    y_original_shuffled = [y_original_shuffled[i] for i in sort_order]\n",
    "    print(\"shuffled originals\")\n",
    "    \n",
    "if len(images_GEN_loaded) >= num_images_to_plot_GEN:\n",
    "    sort_order = sorted(random.sample(range(len(images_GEN_shuffled)), num_images_to_plot_GEN))\n",
    "    images_GEN_shuffled = [images_GEN_shuffled[i] for i in sort_order]\n",
    "    pca_features_GEN_shuffled = [pca_features_GEN_shuffled[i] for i in sort_order]\n",
    "    y_generated_shuffled = [y_generated_shuffled[i] for i in sort_order]\n",
    "    print(\"shuffled generated\")\n",
    "    \n",
    "print(\"After shuffling:\")\n",
    "\n",
    "print(\"Shuffled Original: images\", len(images_ORIG_shuffled), \"features\", len(pca_features_ORIG_shuffled),\"x\",len(pca_features_ORIG_shuffled[0]))\n",
    "print(\"Shuffled Generated: images\", len(images_GEN_shuffled),\"features\", len(pca_features_GEN_shuffled),\"x\",len(pca_features_GEN_shuffled[0]))\n",
    "\n",
    "images = np.concatenate((images_ORIG_shuffled, images_GEN_shuffled), axis=0)\n",
    "pca_features = np.concatenate((pca_features_ORIG_shuffled, pca_features_GEN_shuffled), axis=0)\n",
    "y = np.concatenate((y_original_shuffled, y_generated_shuffled), axis=0)\n",
    "\n",
    "print(\"Combined: images\", len(images), \"features\", len(pca_features),\"x\", len(pca_features[0]))\n",
    "print(\"Y: \", len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't run PCA!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data processing\n",
    "# X = features of both\n",
    "# Y = 0 if real, 1 if generated\n",
    "\n",
    "data = pca_features\n",
    "labels = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip data_train, data_test, labels_train, labels_test = train_test_split(data, labels, test_size=0.33) #random_state=42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "inputs = Input(shape=(512,))\n",
    "\n",
    "x = Dense(512, activation='relu')(inputs)\n",
    "x = Dense(300, activation='relu')(x)\n",
    "x = Dense(2, activation='relu', name='dense_2_layer')(inputs)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# This creates a model that includes\n",
    "# the Input layer and three Dense layers\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "#  adam rmsprop\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.6721 - acc: 0.5800\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.6553 - acc: 0.6106\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.6486 - acc: 0.6175\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.6441 - acc: 0.6225\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.6413 - acc: 0.6271\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.6397 - acc: 0.6274\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 0.6384 - acc: 0.6297\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.6372 - acc: 0.6299\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.6366 - acc: 0.6311\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.6359 - acc: 0.6325\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 11s 184us/step - loss: 0.6352 - acc: 0.6317\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.6346 - acc: 0.6326\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.6341 - acc: 0.6335\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.6338 - acc: 0.6330\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.6334 - acc: 0.6337\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.6331 - acc: 0.6323\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 10s 172us/step - loss: 0.6328 - acc: 0.6330\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.6325 - acc: 0.6326\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.6322 - acc: 0.6325\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.6321 - acc: 0.6323\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.6318 - acc: 0.6325\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 0.6316 - acc: 0.6325\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 8s 139us/step - loss: 0.6316 - acc: 0.6330\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.6315 - acc: 0.6315\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.6310 - acc: 0.6310\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.6315 - acc: 0.6316\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.6311 - acc: 0.6303\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.6311 - acc: 0.6315\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.6309 - acc: 0.6294\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 0.6308 - acc: 0.6307\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.6308 - acc: 0.6282\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.6304 - acc: 0.6304\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.6307 - acc: 0.6282\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.6305 - acc: 0.6287\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.6304 - acc: 0.6276\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.6303 - acc: 0.6270\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.6306 - acc: 0.6256\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.6301 - acc: 0.6265\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.6298 - acc: 0.6255\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.6299 - acc: 0.6262\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.6298 - acc: 0.6237\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.6296 - acc: 0.6240\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.6299 - acc: 0.6233\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.6292 - acc: 0.6235\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.6295 - acc: 0.6224\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.6292 - acc: 0.6219\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.6289 - acc: 0.6217\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 12s 198us/step - loss: 0.6289 - acc: 0.6211\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 10s 158us/step - loss: 0.6292 - acc: 0.6205\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.6286 - acc: 0.6204\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.6284 - acc: 0.6225\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.6285 - acc: 0.6216\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.6280 - acc: 0.6236\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.6285 - acc: 0.6242\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.6284 - acc: 0.6245\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.6280 - acc: 0.6256\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 11s 184us/step - loss: 0.6286 - acc: 0.6240\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.6284 - acc: 0.6239\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.6282 - acc: 0.6255\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.6282 - acc: 0.6240\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.6280 - acc: 0.6248\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.6279 - acc: 0.6238\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.6281 - acc: 0.6245\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.6280 - acc: 0.6256\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.6279 - acc: 0.6251\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.6279 - acc: 0.6255\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.6279 - acc: 0.6252\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.6278 - acc: 0.6248\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.6277 - acc: 0.6263\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.6277 - acc: 0.6252\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.6277 - acc: 0.6254\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.6277 - acc: 0.6257\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 11s 179us/step - loss: 0.6278 - acc: 0.6250\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.6278 - acc: 0.6252\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.6277 - acc: 0.6255\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.6275 - acc: 0.6264\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.6276 - acc: 0.6249\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.6275 - acc: 0.6244\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.6276 - acc: 0.6254\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 11s 178us/step - loss: 0.6275 - acc: 0.6258\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.6275 - acc: 0.6256\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.6277 - acc: 0.6265\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.6275 - acc: 0.6263\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 10s 158us/step - loss: 0.6275 - acc: 0.6265\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.6273 - acc: 0.6275\n",
      "Epoch 86/100\n",
      "28672/60000 [=============>................] - ETA: 4s - loss: 0.6261 - acc: 0.6278"
     ]
    }
   ],
   "source": [
    "#data_train, data_test, labels_train, labels_test\n",
    "\n",
    "#history = model.fit(data_train, labels_train, epochs=100, verbose=1, validation_data=(data_test, labels_test))  # starts training\n",
    "history = model.fit(data, labels, epochs=100, verbose=1)  # starts training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(history.history)\n",
    "fig = plt.figure()\n",
    "plt.title(\"simple model: 512 features input - Dense 512 - 300 - 2 - 1 output\")\n",
    "plt.plot(history.history['loss'], label=\"loss\")\n",
    "plt.plot(history.history['acc'], label=\"acc\")\n",
    "#plt.plot(history.history['val_loss'], label=\"val_loss\")\n",
    "#plt.plot(history.history['val_acc'], label=\"val_acc\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_save_path = \"/home/kangeunsu/ArtML/Embeddings/model_training/512features_Dense512-300-2_1out.pdf\"\n",
    "fig.savefig(plot_save_path, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40200 samples, validate on 19800 samples\n",
      "Epoch 1/100\n",
      "40200/40200 [==============================] - 8s 189us/step - loss: 0.6128 - acc: 0.6523 - val_loss: 0.5755 - val_acc: 0.6922\n",
      "Epoch 2/100\n",
      "40200/40200 [==============================] - 7s 186us/step - loss: 0.5443 - acc: 0.7188 - val_loss: 0.5271 - val_acc: 0.7339\n",
      "Epoch 3/100\n",
      "40200/40200 [==============================] - 7s 185us/step - loss: 0.5085 - acc: 0.7481 - val_loss: 0.5105 - val_acc: 0.7473\n",
      "Epoch 4/100\n",
      "40200/40200 [==============================] - 7s 186us/step - loss: 0.4810 - acc: 0.7673 - val_loss: 0.5042 - val_acc: 0.7512\n",
      "Epoch 5/100\n",
      "40200/40200 [==============================] - 7s 180us/step - loss: 0.4591 - acc: 0.7809 - val_loss: 0.5015 - val_acc: 0.7575\n",
      "Epoch 6/100\n",
      "40200/40200 [==============================] - 7s 176us/step - loss: 0.4372 - acc: 0.7953 - val_loss: 0.4897 - val_acc: 0.7649\n",
      "Epoch 7/100\n",
      "40200/40200 [==============================] - 7s 182us/step - loss: 0.4173 - acc: 0.8041 - val_loss: 0.4855 - val_acc: 0.7641\n",
      "Epoch 8/100\n",
      "40200/40200 [==============================] - 7s 182us/step - loss: 0.3987 - acc: 0.8171 - val_loss: 0.4779 - val_acc: 0.7723\n",
      "Epoch 9/100\n",
      "40200/40200 [==============================] - 7s 184us/step - loss: 0.3791 - acc: 0.8266 - val_loss: 0.4765 - val_acc: 0.7788\n",
      "Epoch 10/100\n",
      "40200/40200 [==============================] - 7s 178us/step - loss: 0.3637 - acc: 0.8348 - val_loss: 0.4850 - val_acc: 0.7759\n",
      "Epoch 11/100\n",
      "40200/40200 [==============================] - 7s 186us/step - loss: 0.3468 - acc: 0.8448 - val_loss: 0.4805 - val_acc: 0.7788\n",
      "Epoch 12/100\n",
      "40200/40200 [==============================] - 7s 182us/step - loss: 0.3306 - acc: 0.8530 - val_loss: 0.4806 - val_acc: 0.7806\n",
      "Epoch 13/100\n",
      "40200/40200 [==============================] - 7s 181us/step - loss: 0.3146 - acc: 0.8614 - val_loss: 0.4885 - val_acc: 0.7798\n",
      "Epoch 14/100\n",
      "40200/40200 [==============================] - 7s 186us/step - loss: 0.2997 - acc: 0.8697 - val_loss: 0.5019 - val_acc: 0.7787\n",
      "Epoch 15/100\n",
      "40200/40200 [==============================] - 7s 182us/step - loss: 0.2848 - acc: 0.8790 - val_loss: 0.4857 - val_acc: 0.7902\n",
      "Epoch 16/100\n",
      "40200/40200 [==============================] - 7s 184us/step - loss: 0.2716 - acc: 0.8848 - val_loss: 0.5024 - val_acc: 0.7857\n",
      "Epoch 17/100\n",
      "40200/40200 [==============================] - 7s 181us/step - loss: 0.2579 - acc: 0.8902 - val_loss: 0.5075 - val_acc: 0.7880\n",
      "Epoch 18/100\n",
      "40200/40200 [==============================] - 7s 182us/step - loss: 0.2442 - acc: 0.8972 - val_loss: 0.5403 - val_acc: 0.7875\n",
      "Epoch 19/100\n",
      "40200/40200 [==============================] - 7s 183us/step - loss: 0.2334 - acc: 0.9012 - val_loss: 0.5356 - val_acc: 0.7846\n",
      "Epoch 20/100\n",
      "40200/40200 [==============================] - 7s 184us/step - loss: 0.2192 - acc: 0.9091 - val_loss: 0.5126 - val_acc: 0.7969\n",
      "Epoch 21/100\n",
      "40200/40200 [==============================] - 7s 185us/step - loss: 0.2115 - acc: 0.9133 - val_loss: 0.5247 - val_acc: 0.7959\n",
      "Epoch 22/100\n",
      "40200/40200 [==============================] - 7s 186us/step - loss: 0.2008 - acc: 0.9160 - val_loss: 0.5395 - val_acc: 0.7985\n",
      "Epoch 23/100\n",
      "40200/40200 [==============================] - 7s 182us/step - loss: 0.1903 - acc: 0.9233 - val_loss: 0.5524 - val_acc: 0.7942\n",
      "Epoch 24/100\n",
      "40200/40200 [==============================] - 7s 176us/step - loss: 0.1800 - acc: 0.9273 - val_loss: 0.5657 - val_acc: 0.7985\n",
      "Epoch 25/100\n",
      "40200/40200 [==============================] - 7s 185us/step - loss: 0.1716 - acc: 0.9313 - val_loss: 0.5659 - val_acc: 0.7982\n",
      "Epoch 26/100\n",
      "40200/40200 [==============================] - 7s 186us/step - loss: 0.1641 - acc: 0.9343 - val_loss: 0.6333 - val_acc: 0.7786\n",
      "Epoch 27/100\n",
      "40200/40200 [==============================] - 7s 186us/step - loss: 0.1532 - acc: 0.9389 - val_loss: 0.6015 - val_acc: 0.7964\n",
      "Epoch 28/100\n",
      "40200/40200 [==============================] - 7s 177us/step - loss: 0.1479 - acc: 0.9414 - val_loss: 0.6079 - val_acc: 0.7941\n",
      "Epoch 29/100\n",
      "40200/40200 [==============================] - 7s 179us/step - loss: 0.1412 - acc: 0.9443 - val_loss: 0.6339 - val_acc: 0.7907\n",
      "Epoch 30/100\n",
      "40200/40200 [==============================] - 7s 185us/step - loss: 0.1352 - acc: 0.9466 - val_loss: 0.6497 - val_acc: 0.7951\n",
      "Epoch 31/100\n",
      "40200/40200 [==============================] - 7s 179us/step - loss: 0.1262 - acc: 0.9502 - val_loss: 0.6653 - val_acc: 0.7919\n",
      "Epoch 32/100\n",
      "40200/40200 [==============================] - 7s 179us/step - loss: 0.1188 - acc: 0.9541 - val_loss: 0.6619 - val_acc: 0.7975\n",
      "Epoch 33/100\n",
      "40200/40200 [==============================] - 7s 183us/step - loss: 0.1130 - acc: 0.9571 - val_loss: 0.6970 - val_acc: 0.7924\n",
      "Epoch 34/100\n",
      "40200/40200 [==============================] - 7s 183us/step - loss: 0.1063 - acc: 0.9609 - val_loss: 0.7019 - val_acc: 0.7942\n",
      "Epoch 35/100\n",
      "40200/40200 [==============================] - 7s 182us/step - loss: 0.1035 - acc: 0.9607 - val_loss: 0.7267 - val_acc: 0.7916\n",
      "Epoch 36/100\n",
      "40200/40200 [==============================] - 7s 179us/step - loss: 0.0983 - acc: 0.9628 - val_loss: 0.7515 - val_acc: 0.7930\n",
      "Epoch 37/100\n",
      "40200/40200 [==============================] - 7s 184us/step - loss: 0.0936 - acc: 0.9647 - val_loss: 0.7452 - val_acc: 0.7947\n",
      "Epoch 38/100\n",
      "40200/40200 [==============================] - 7s 184us/step - loss: 0.0895 - acc: 0.9666 - val_loss: 0.7613 - val_acc: 0.7960\n",
      "Epoch 39/100\n",
      "40200/40200 [==============================] - 7s 182us/step - loss: 0.0809 - acc: 0.9704 - val_loss: 0.7945 - val_acc: 0.7877\n",
      "Epoch 40/100\n",
      "40200/40200 [==============================] - 7s 183us/step - loss: 0.0838 - acc: 0.9689 - val_loss: 0.7865 - val_acc: 0.7932\n",
      "Epoch 41/100\n",
      "40200/40200 [==============================] - 7s 185us/step - loss: 0.0777 - acc: 0.9709 - val_loss: 0.8251 - val_acc: 0.7916\n",
      "Epoch 42/100\n",
      "40200/40200 [==============================] - 7s 182us/step - loss: 0.0728 - acc: 0.9743 - val_loss: 0.8297 - val_acc: 0.7935\n",
      "Epoch 43/100\n",
      "40200/40200 [==============================] - 7s 184us/step - loss: 0.0723 - acc: 0.9741 - val_loss: 0.8400 - val_acc: 0.7912\n",
      "Epoch 44/100\n",
      "40200/40200 [==============================] - 7s 182us/step - loss: 0.0646 - acc: 0.9772 - val_loss: 0.9071 - val_acc: 0.7808\n",
      "Epoch 45/100\n",
      "40200/40200 [==============================] - 7s 184us/step - loss: 0.0640 - acc: 0.9766 - val_loss: 0.8650 - val_acc: 0.7961\n",
      "Epoch 46/100\n",
      "40200/40200 [==============================] - 7s 177us/step - loss: 0.0617 - acc: 0.9771 - val_loss: 0.8657 - val_acc: 0.7932\n",
      "Epoch 47/100\n",
      "40200/40200 [==============================] - 7s 184us/step - loss: 0.0602 - acc: 0.9775 - val_loss: 0.8910 - val_acc: 0.7947\n",
      "Epoch 48/100\n",
      "40200/40200 [==============================] - 7s 176us/step - loss: 0.0580 - acc: 0.9791 - val_loss: 0.9293 - val_acc: 0.7953\n",
      "Epoch 49/100\n",
      "40200/40200 [==============================] - 7s 184us/step - loss: 0.0543 - acc: 0.9812 - val_loss: 0.8949 - val_acc: 0.7966\n",
      "Epoch 50/100\n",
      "40200/40200 [==============================] - 7s 186us/step - loss: 0.0526 - acc: 0.9816 - val_loss: 0.9193 - val_acc: 0.7938\n",
      "Epoch 51/100\n",
      "40200/40200 [==============================] - 7s 183us/step - loss: 0.0526 - acc: 0.9816 - val_loss: 0.9440 - val_acc: 0.7907\n",
      "Epoch 52/100\n",
      "40200/40200 [==============================] - 7s 184us/step - loss: 0.0545 - acc: 0.9803 - val_loss: 0.9565 - val_acc: 0.7930\n",
      "Epoch 53/100\n",
      "40200/40200 [==============================] - 7s 186us/step - loss: 0.0443 - acc: 0.9851 - val_loss: 0.9899 - val_acc: 0.7926\n",
      "Epoch 54/100\n",
      "40200/40200 [==============================] - 7s 185us/step - loss: 0.0482 - acc: 0.9828 - val_loss: 0.9823 - val_acc: 0.7945\n",
      "Epoch 55/100\n",
      "40200/40200 [==============================] - 7s 178us/step - loss: 0.0443 - acc: 0.9845 - val_loss: 1.0032 - val_acc: 0.7925\n",
      "Epoch 56/100\n",
      "40200/40200 [==============================] - 7s 183us/step - loss: 0.0452 - acc: 0.9838 - val_loss: 1.0617 - val_acc: 0.7906\n",
      "Epoch 57/100\n",
      "40200/40200 [==============================] - 7s 184us/step - loss: 0.0475 - acc: 0.9835 - val_loss: 1.0277 - val_acc: 0.7886\n",
      "Epoch 58/100\n",
      "40200/40200 [==============================] - 7s 184us/step - loss: 0.0402 - acc: 0.9861 - val_loss: 1.0483 - val_acc: 0.7935\n",
      "Epoch 59/100\n",
      "40200/40200 [==============================] - 7s 185us/step - loss: 0.0396 - acc: 0.9861 - val_loss: 1.0908 - val_acc: 0.7854\n",
      "Epoch 60/100\n",
      "40200/40200 [==============================] - 7s 183us/step - loss: 0.0420 - acc: 0.9852 - val_loss: 1.1147 - val_acc: 0.7891\n",
      "Epoch 61/100\n",
      "40200/40200 [==============================] - 7s 185us/step - loss: 0.0409 - acc: 0.9856 - val_loss: 1.0398 - val_acc: 0.7980\n",
      "Epoch 62/100\n",
      "40200/40200 [==============================] - 7s 181us/step - loss: 0.0355 - acc: 0.9877 - val_loss: 1.0941 - val_acc: 0.7882\n",
      "Epoch 63/100\n",
      "40200/40200 [==============================] - 7s 186us/step - loss: 0.0441 - acc: 0.9844 - val_loss: 1.0540 - val_acc: 0.7929\n",
      "Epoch 64/100\n",
      "40200/40200 [==============================] - 7s 186us/step - loss: 0.0322 - acc: 0.9897 - val_loss: 1.0934 - val_acc: 0.7934\n",
      "Epoch 65/100\n",
      "40200/40200 [==============================] - 7s 185us/step - loss: 0.0380 - acc: 0.9867 - val_loss: 1.1360 - val_acc: 0.7883\n",
      "Epoch 66/100\n",
      "40200/40200 [==============================] - 7s 180us/step - loss: 0.0350 - acc: 0.9882 - val_loss: 1.1294 - val_acc: 0.7908\n",
      "Epoch 67/100\n",
      "40200/40200 [==============================] - 7s 185us/step - loss: 0.0394 - acc: 0.9853 - val_loss: 1.1172 - val_acc: 0.7932\n",
      "Epoch 68/100\n",
      "40200/40200 [==============================] - 7s 185us/step - loss: 0.0328 - acc: 0.9886 - val_loss: 1.1220 - val_acc: 0.7894\n",
      "Epoch 69/100\n",
      "40200/40200 [==============================] - 7s 182us/step - loss: 0.0345 - acc: 0.9885 - val_loss: 1.1666 - val_acc: 0.7898\n",
      "Epoch 70/100\n",
      "40200/40200 [==============================] - 8s 191us/step - loss: 0.0323 - acc: 0.9889 - val_loss: 1.1918 - val_acc: 0.7854\n",
      "Epoch 71/100\n",
      "40200/40200 [==============================] - 7s 184us/step - loss: 0.0316 - acc: 0.9886 - val_loss: 1.1909 - val_acc: 0.7867\n",
      "Epoch 72/100\n",
      "40200/40200 [==============================] - 8s 187us/step - loss: 0.0308 - acc: 0.9896 - val_loss: 1.2309 - val_acc: 0.7887\n",
      "Epoch 73/100\n",
      "40200/40200 [==============================] - 7s 182us/step - loss: 0.0326 - acc: 0.9887 - val_loss: 1.2502 - val_acc: 0.7849\n",
      "Epoch 74/100\n",
      "40200/40200 [==============================] - 7s 186us/step - loss: 0.0341 - acc: 0.9883 - val_loss: 1.2322 - val_acc: 0.7818\n",
      "Epoch 75/100\n",
      "40200/40200 [==============================] - 7s 184us/step - loss: 0.0264 - acc: 0.9907 - val_loss: 1.2130 - val_acc: 0.7885\n",
      "Epoch 76/100\n",
      "40200/40200 [==============================] - 7s 179us/step - loss: 0.0322 - acc: 0.9891 - val_loss: 1.2272 - val_acc: 0.7877\n",
      "Epoch 77/100\n",
      "40200/40200 [==============================] - 7s 184us/step - loss: 0.0272 - acc: 0.9911 - val_loss: 1.2553 - val_acc: 0.7839\n",
      "Epoch 78/100\n",
      "40200/40200 [==============================] - 7s 184us/step - loss: 0.0336 - acc: 0.9886 - val_loss: 1.1914 - val_acc: 0.7891\n",
      "Epoch 79/100\n",
      "40200/40200 [==============================] - 7s 182us/step - loss: 0.0249 - acc: 0.9911 - val_loss: 1.1933 - val_acc: 0.7923\n",
      "Epoch 80/100\n",
      "40200/40200 [==============================] - 7s 184us/step - loss: 0.0301 - acc: 0.9897 - val_loss: 1.2208 - val_acc: 0.7903\n",
      "Epoch 81/100\n",
      "40200/40200 [==============================] - 7s 175us/step - loss: 0.0214 - acc: 0.9930 - val_loss: 1.2889 - val_acc: 0.7876\n",
      "Epoch 82/100\n",
      "40200/40200 [==============================] - 7s 183us/step - loss: 0.0310 - acc: 0.9892 - val_loss: 1.2347 - val_acc: 0.7921\n",
      "Epoch 83/100\n",
      "40200/40200 [==============================] - 7s 179us/step - loss: 0.0241 - acc: 0.9916 - val_loss: 1.2972 - val_acc: 0.7830\n",
      "Epoch 84/100\n",
      "40200/40200 [==============================] - 7s 184us/step - loss: 0.0269 - acc: 0.9907 - val_loss: 1.2996 - val_acc: 0.7865\n",
      "Epoch 85/100\n",
      "40200/40200 [==============================] - 7s 184us/step - loss: 0.0255 - acc: 0.9919 - val_loss: 1.3818 - val_acc: 0.7823\n",
      "Epoch 86/100\n",
      "40200/40200 [==============================] - 7s 180us/step - loss: 0.0274 - acc: 0.9904 - val_loss: 1.2567 - val_acc: 0.7899\n",
      "Epoch 87/100\n",
      "40200/40200 [==============================] - 7s 180us/step - loss: 0.0219 - acc: 0.9923 - val_loss: 1.3061 - val_acc: 0.7919\n",
      "Epoch 88/100\n",
      "40200/40200 [==============================] - 7s 184us/step - loss: 0.0274 - acc: 0.9902 - val_loss: 1.2649 - val_acc: 0.7916\n",
      "Epoch 89/100\n",
      "40200/40200 [==============================] - 7s 184us/step - loss: 0.0236 - acc: 0.9918 - val_loss: 1.2598 - val_acc: 0.7917\n",
      "Epoch 90/100\n",
      "40200/40200 [==============================] - 7s 184us/step - loss: 0.0251 - acc: 0.9913 - val_loss: 1.3145 - val_acc: 0.7867\n",
      "Epoch 91/100\n",
      "40200/40200 [==============================] - 7s 183us/step - loss: 0.0217 - acc: 0.9925 - val_loss: 1.3033 - val_acc: 0.7908\n",
      "Epoch 92/100\n",
      "40200/40200 [==============================] - 7s 183us/step - loss: 0.0265 - acc: 0.9901 - val_loss: 1.3321 - val_acc: 0.7902\n",
      "Epoch 93/100\n",
      "40200/40200 [==============================] - 7s 185us/step - loss: 0.0244 - acc: 0.9911 - val_loss: 1.3301 - val_acc: 0.7865\n",
      "Epoch 94/100\n",
      "40200/40200 [==============================] - 7s 183us/step - loss: 0.0197 - acc: 0.9929 - val_loss: 1.3582 - val_acc: 0.7864\n",
      "Epoch 95/100\n",
      "40200/40200 [==============================] - 7s 185us/step - loss: 0.0252 - acc: 0.9912 - val_loss: 1.3421 - val_acc: 0.7870\n",
      "Epoch 96/100\n",
      "40200/40200 [==============================] - 8s 187us/step - loss: 0.0212 - acc: 0.9929 - val_loss: 1.3862 - val_acc: 0.7821\n",
      "Epoch 97/100\n",
      "40200/40200 [==============================] - 7s 184us/step - loss: 0.0240 - acc: 0.9922 - val_loss: 1.3445 - val_acc: 0.7918\n",
      "Epoch 98/100\n",
      "40200/40200 [==============================] - 7s 185us/step - loss: 0.0200 - acc: 0.9934 - val_loss: 1.3486 - val_acc: 0.7896\n",
      "Epoch 99/100\n",
      "40200/40200 [==============================] - 7s 184us/step - loss: 0.0275 - acc: 0.9901 - val_loss: 1.3684 - val_acc: 0.7860\n",
      "Epoch 100/100\n",
      "40200/40200 [==============================] - 8s 188us/step - loss: 0.0195 - acc: 0.9935 - val_loss: 1.3781 - val_acc: 0.7874\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "inputs = Input(shape=(300,))\n",
    "\n",
    "x = Dense(256, activation='relu')(inputs)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# This creates a model that includes\n",
    "# the Input layer and three Dense layers\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "#  adam rmsprop\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(data_train, labels_train, epochs=100, verbose=1, validation_data=(data_test, labels_test))  # starts training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f083c1c6c50>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f08b4644b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.title(\"two layer model\")\n",
    "plt.plot(history.history['loss'], label=\"loss\")\n",
    "plt.plot(history.history['acc'], label=\"acc\")\n",
    "plt.plot(history.history['val_loss'], label=\"val_loss\")\n",
    "plt.plot(history.history['val_acc'], label=\"val_acc\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
